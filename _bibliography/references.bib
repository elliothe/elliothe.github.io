@article{rakin2020t,
  title={T-BFA: Targeted Bit-Flip Adversarial Weight Attack},
  author={Rakin, Adnan Siraj and He, Zhezhi and Li, Jingtao and Yao, Fan and Chakrabarti, Chaitali and Fan, Deliang},
  journal={arXiv preprint arXiv:2007.12336},
  year={2020},
  preprint={https://arxiv.org/pdf/2007.12336.pdf}
}


@article{Durjoy2020ACSNANO,
  title={2D MoS2 Based Threshold Switching Memristor For Artificial Neuron},
  author={Dev, Durjoy and Krishnaprasad, Adithi and Shawkat, Mashiyat and He, Zhezhi and Das, Sonali and Chung, Hee-Suk and Fan, Deliang and Jung, Yeonwoong and Roy, Tania},
  abstract={In this work, we use a two-terminal 2D MoS2-based memristive device to emulate an artificial neuron. The Au/MoS2/Ag device exhibits volatile resistance switching characteristics with a low threshold voltage and a high ON-OFF ratio of 106, originating from an Ag diffusion-based filamentary process. The leaky integrate-and-fire neuron implemented with this device successfully emulates the key characteristics of a biological neuron.},
  journal={IEEE Electron Device Letters (EDL)},
  year={2020},
  keywords={journal},
  annote={(Accepted)},
  link={https://ieeexplore.ieee.org/document/9069258}
}


@article{he2020defend,
  title={Defending and Harnessing the Bit-Flip based Adversarial Weight Attack},
  author={He, Zhezhi and Rakin, Adnan Siraj and Li, Jingtao and Chakrabarti, Chaitali and Fan, Deliang},
  journal={Conference on Computer Vision and Pattern Recognition (CVPR)},
  abstract={Recently, a new paradigm of the adversarial attack on the quantized neural network weights has attracted great attention, namely, the Bit-Flip based adversarial weight attack, aka. Bit-Flip Attack (BFA). BFA has shown extraordinary attacking ability, where the adversary can malfunction a quantized Deep Neural Network (DNN) as a random guess, through malicious bit-flips on a small set of vulnerable weight bits (e.g., 13 out of 93 millions bits of 8-bit quantized ResNet-18). However, there are no effective defensive methods to enhance the fault-tolerance capability of DNN against such BFA. In this work, we conduct comprehensive investigations on BFA and propose to leverage binarizationaware training and its relaxation – piece-wise clustering as simple and effective countermeasures to BFA. The experiments show that, for BFA to achieve the identical prediction accuracy degradation (e.g., below 11\% on CIFAR-10), it requires 19.3× and 480.1× more effective malicious bitflips on ResNet-20 and VGG-11 respectively, compared to defend-free counterparts.},
  year={2020},
  keywords={conference},
  preprint={https://dfan.engineering.asu.edu/wp-content/uploads/2020/04/CVPR2020_defense.pdf},
  link={https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Defending_and_Harnessing_the_Bit-Flip_Based_Adversarial_Weight_Attack_CVPR_2020_paper.pdf},
  code={https://github.com/elliothe/BFA},
  annote={(Accepted)}
}

@article{rakin2019tbt,
  title={TBT: Targeted Neural Network Attack with Bit Trojan},
  author={Rakin, Adnan Siraj and He, Zhezhi and Fan, Deliang},
  journal={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  keywords={conference},
  annote={(Accepted)},
  link={https://openaccess.thecvf.com/content_CVPR_2020/papers/Rakin_TBT_Targeted_Neural_Network_Attack_With_Bit_Trojan_CVPR_2020_paper.pdf},
  code={https://github.com/adnansirajrakin/TBT-2020},
  preprint={https://arxiv.org/pdf/1909.05193.pdf}
}

@article{yang2020nonuniform,
  title={Non-uniform DNN Structured Subnets Sampling for Dynamic Inference},
  author={Yang, Li and He, Zhezhi and Fan, Deliang},
  journal={57th Design Automation Conference (DAC)},
  year={2020},
  keywords={conference},
  annote={(Accepted)}
}

@article{li2020defend,
  title={Defending Bit-Flip Attack through DNN Weight Reconstruction},
  author={Li, Jingtao and Rakin, Adnan Siraj and Xiong, Yan and Chang, Liangliang and He, Zhezhi and Fan, Deliang and Chakrabarti, Chaitali},
  journal={57th Design Automation Conference (DAC)},
  year={2020},
  keywords={conference},
  annote={(Accepted)},

}

@article{he2020tnnls,
  title={Non-Structured DNN Weight Pruning--Is It Beneficial in Any Platform?},
  author={Ma, Xiaolong and Lin, Sheng and Ye, Shaokai and He, Zhezhi and Zhang, Linfeng and Yuan, Geng and Huat Tan, Sia and Li, Zhengang and Fan, Deliang and Qian, Xuehai and others},
  journal={IEEE Transactions on Neural Networks and Learning Systems (TNNLS)},
  publisher={IEEE},
  year={2020},
  keywords={journal},
  annote={(Accepted)},
  preprint={https://www.researchgate.net/profile/Zhezhi_He/publication/334248569_Non-structured_DNN_Weight_Pruning_Considered_Harmful/links/5e8f8a7e4585150839ceaa72/Non-structured-DNN-Weight-Pruning-Considered-Harmful.pdf}
}



@article{yang2019harmonious,
  title={Harmonious Coexistence of Structured Weight Pruning and Ternarization for Deep Neural Networks},
  author={Yang, Li and He, Zhezhi and Fan, Deliang},
  journal={Thirty-third AAAI Conference on Artificial Intelligence (AAAI)},
  abstract={Deep convolutional neural network (DNN) has demonstrated phenomenal success and been widely used in many computer vision tasks. However, its enormous model size and high computing complexity prohibits its wide deployment into resource limited embedded system, such as FPGA and mGPU. As the two most widely adopted model compression techniques, weight pruning and quantization compress DNN model through introducing weight sparsity (i.e., forcing partial weights as zeros) and quantizing weights into limited bitwidth values, respectively. Although there are works attempting to combine the weight pruning and quantization, we still observe disharmony between weight pruning and quantization, especially when more aggressive compression schemes (e.g., Structured pruning and low bit-width quantization) are used. In this work, taking FPGA as the test computing platform and Processing Elements (PE) as the basic parallel computing unit, we first propose a PE-wise structured pruning scheme, which introduces weight sparsification with considering of the architecture of PE. In addition, we integrate it with an optimized weight ternarization approach which quantizes weights into ternary values ({−1, 0, +1}), thus converting the dominant convolution operations in DNN from multiplication-and-accumulation (MAC) to addition-only, as well as compressing the original model (from 32-bit floating point to 2-bit ternary representation) by at least 16 times. Then, we investigate and solve the coexistence issue between PE-wise Structured pruning and ternarization, through proposing a Weight Penalty Clipping (WPC) technique with self-adapting threshold. Our experiment shows that the fusion of our proposed techniques can achieve the best state-of-theart ∼ 21× PE-wise structured compression rate with merely 1.74\%/0.94\% (top-1/top-5) accuracy degradation of ResNet18 on ImageNet dataset.},
  year={2020},
  keywords={conference},
  link={https://www.aaai.org/Papers/AAAI/2020GB/AAAI-YangL.9289.pdf},
  annote={(Spotlight)}
}


@article{he2020sparse,
  title={Sparse BD-Net: A Multiplication-less DNN with Sparse Binarized Depth-wise Separable Convolution},
  author={He, Zhezhi and Yang, Li and Angizi, Shaahin and Rakin, Adnan Siraj and Fan, Deliang},
  journal={ACM Journal on Emerging Technologies in Computing Systems (JETC)},
  volume={16},
  number={2},
  pages={1--24},
  year={2020},
  publisher={ACM New York, NY, USA},
  keywords={journal},
  link={https://dl.acm.org/doi/10.1145/3369391}
}


@article{he2020bioinformatics,
  title={Network-based multi-task learning models for biomarker selection and cancer outcome prediction},
  author={Wang, Zhibo and He, Zhezhi and Shah, Milan and Zhang, Teng and Fan, Deliang and Zhang, Wei},
  journal={Oxford academic Bioinformatics},
  abstract={Detecting cancer gene expression and transcriptome changes with mRNA-sequencing or array-based data are important for understanding the molecular mechanisms underlying carcinogenesis and cellular events during cancer progression. In previous studies, the differentially expressed genes were detected across patients in one cancer type. These studies ignored the role of mRNA expression changes in driving tumorigenic mechanisms that are either universal or specific in different tumor types. To address the problem, we introduce two network-based multi-task learning frameworks, NetML and NetSML, to discover common differentially expressed genes shared across different cancer types as well as differentially expressed genes specific to each cancer type. The proposed frameworks consider the common latent gene co-expression modules and gene–sample biclusters underlying the multiple cancer datasets to learn the knowledge crossing different tumor types. Large-scale experiments on simulations and real cancer high-throughput datasets validate that the proposed network-based multi-task learning frameworks perform better sample classification compared with the models without the knowledge sharing across different cancer types. The common and cancer-specific molecular signatures detected by multi-task learning frameworks on The Cancer Genome Atlas ovarian, breast and prostate cancer datasets are correlated with the known marker genes and enriched in cancer-relevant Kyoto Encyclopedia of Genes and Genome pathways and gene ontology terms.},
  year={2019},
  keywords  = {journal},
  link={https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btz809/5613179},
  code={https://github.com/compbiolabucf/NetML}
}


@article{angizi2020hybrid,
  title={Hybrid Spin-CMOS Polymorphic Logic Gate With Application in In-Memory Computing},
  author={Angizi, Shaahin and He, Zhezhi and Chen, An and Fan, Deliang},
  journal={IEEE Transactions on Magnetics},
  volume={56},
  number={2},
  pages={1--15},
  year={2020},
  publisher={IEEE},
  keywords  = {journal},
  link={https://ieeexplore.ieee.org/abstract/document/8956045}
}


@inproceedings{dev2019artificial,
  title={Artificial Neuron using Ag/2D-MoS 2/Au Threshold Switching Memristor},
  author={Dev, Durjoy and Krishnaprasad, Adithi and He, Zhezhi and Das, Sonali and Shawkat, Mashiyat Sumaiya and Manley, Madison and Aina, Olaleye and Fan, Deliang and Jung, Yeonwoong and Roy, Tania},
 abstract={The phenomenal evolution of information and communication drives future technologies towards highly parallel, energy-efficient self-learning systems like the human brain. The limitations of current von Neumann computation systems have paved the way for artificial neural networks (ANN) to meet these criteria. The memristor has become an emerging candidate to realize ANN through emulating biological synapse and neuron behavior. We previously reported an artificial neuron with 2D Mos2 and graphene electrode, but the operating voltage was high, and the output current was low. In this work, we harness threshold switching in Mos2 enabled by Ag electrode, to emulate integration and firing behavior of neuron and demonstrate digit recognition application with these devices. The simple vertical structure of Ag/MoS2/Au threshold switching memristor (TSM), with very low threshold voltage (Vth=0.4−0.5V) , displays the four crucial features of neuron─ all-or-nothing spiking, threshold-driven firing, post firing refractory period and stimulus strength based frequency response.},
  booktitle={Device Research Conference (DRC)},
  pages={193--194},
  year={2019},
  organization={IEEE},
  keywords  = {conference},
  link={https://ieeexplore.ieee.org/abstract/document/9046335}
}


@inproceedings{he2019PBS,
  title={Bit-Flip Attack: Crushing Neural Network with Progressive Bit Search},
  author={He<sup>=</sup>, Zhezhi and Rakin<sup>=</sup>, Adnan Siraj and Fan, Deliang},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2019},
  keywords={conference},
  link={http://openaccess.thecvf.com/content_ICCV_2019/papers/Rakin_Bit-Flip_Attack_Crushing_Neural_Network_With_Progressive_Bit_Search_ICCV_2019_paper.pdf},
  code={https://github.com/elliothe/Neural_Network_Weight_Attack}
}


@inproceedings{angizi2019accelerating,
author={Angizi, Shaahin and He, Zhezhi and Reis, Dayane and Hu, Sharon Xiaobo and Tsai, Wilman and Lin, Shy Jay and Fan, Deliang},
booktitle={2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
title={Accelerating Deep Neural Networks in Processing-in-Memory Platforms: Analog or Digital Approach?},
year={2019},
pages={197-202},
keywords={conference},
link={https://ieeexplore.ieee.org/abstract/document/8839490}
}

@article{he2019parametric,
  title={Parametric Noise Injection: Trainable Randomness to Improve Deep Neural Network Robustness against Adversarial Attack},
  author={He=, Zhezhi and Rakin=, Adnan Siraj and Fan, Deliang},
  journal={Conference on Computer Vision and Pattern (CVPR)},
  year={2019},
  keywords  = {conference},
  link={https://github.com/elliothe/CVPR_2019_PNI/blob/master/CVPR19_PNI.pdf},
  code={https://github.com/elliothe/CVPR_2019_PNI}
}


@article{he2019simultaneously,
  title={Simultaneously Optimizing Weight and Quantizer of Ternary Neural Network using Truncated Gaussian Approximation},
  author={He, Zhezhi and Fan, Deliang},
  journal={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019},
  keywords  = {conference},
  link={http://openaccess.thecvf.com/content_CVPR_2019/html/He_Simultaneously_Optimizing_Weight_and_Quantizer_of_Ternary_Neural_Network_Using_CVPR_2019_paper.html}
}


@article{he2019NIA,
  title={Noise Injection Adaption: End-to-End ReRAM Crossbar Non-ideal Effect Adaption for Neural Network Mapping},
  author={He, Zhezhi and Lin, Jie and Ewetz, Rickard and Yuan, Jiann-Shiun and Fan, Deliang},
  journal={56-th Design Automation Conference (DAC)},
  year={2019},
  publisher={ACM},
  keywords  = {conference},
  link={https://dl.acm.org/doi/10.1145/3316781.3317870},
  code={https://github.com/elliothe/pytorx}
}

@article{he2019optimize,
  title={Optimize Deep Convolutional Neural Network with Ternarized Weights and High Accuracy},
  author={He, Zhezhi and Gong, Boqing and Fan, Deliang},
  journal={IEEE Winter Conference on Applications of Computer Vision (WACV)},
  year={2019},
  keywords  = {conference},
  link={https://ieeexplore.ieee.org/abstract/document/8658565},
  code={https://github.com/elliothe/Ternarized_Neural_Network}
}

@article{he2019BYOLO,
  title={Binarized Depthwise Separable Neural Network for Object Tracking in FPGA},
  author={Yang, Li and He, Zhezhi and Fan, Deliang},
  journal={Great Lakes Symposium on VLSI (GLSVLSI)},
  year={2019},
  keywords = {conference},
  link={https://dl.acm.org/doi/10.1145/3299874.3318034}
}

@article{angizi2019mrima,
  title={MRIMA: An MRAM-based In-Memory Accelerator},
  author={Angizi, Shaahin and He, Zhezhi and Awad, Amro and Fan, Deliang},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  year={2019},
  publisher={IEEE},
  keywords  = {journal},
  link = {https://ieeexplore.ieee.org/abstract/document/8675492}
}

@inproceedings{angizi2019parapim,
  title={ParaPIM: A Parallel Processing-In-Memory Accelerator for Binary-Weight Deep Neural Networks},
  author={Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={Proceedings of the 24th Asia and South Pacific Design Automation Conference (ASP-DAC)},
  pages={127--132},
  year={2019},
  organization={ACM},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/10.1145/3287624.3287644}
}


@inproceedings{angizi2018dima,
  title={DIMA: A Depthwise CNN In-Memory Accelerator},
  author={Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
  pages={1--8},
  year={2018},
  organization={IEEE},
  keywords  = {conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8587671}
}

@inproceedings{rakin2018pim,
  title={PIM-TGAN: A Processing-in-Memory Accelerator for Ternary Generative Adversarial Networks},
  author={Rakin, Adnan Siraj and Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={2018 IEEE 36th International Conference on Computer Design (ICCD)},
  pages={266--273},
  year={2018},
  organization={IEEE},
  keywords  = {conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8615698}
}


@inproceedings{yang2018fully,
  title={A Fully Onchip Binarized Convolutional Neural Network FPGA Impelmentation with Accurate Inference},
  author={Yang, Li and He, Zhezhi and Fan, Deliang},
  booktitle={Proceedings of the International Symposium on Low Power Electronics and Design (ISLPED)},
  pages={50},
  year={2018},
  organization={ACM},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/10.1145/3218603.3218615}
}

@inproceedings{he2018accelerating,
  title={Accelerating Low Bit-Width Deep Convolution Neural Network in MRAM},
  author={He, Zhezhi and Angizi, Shaahin and Fan, Deliang},
  booktitle={2018 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={533--538},
  year={2018},
  organization={IEEE},
  keywords ={conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8429424}
}


@inproceedings{he2018bd,
  title={BD-NET: A Multiplication-Less DNN with Binarized Depthwise Separable Convolution},
  author={He, Zhezhi and Angizi, Shaahin and Rakin, Adnan Siraj and Fan, Deliang},
  booktitle={2018 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={130--135},
  year={2018},
  organization={IEEE},
  keywords  = {conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8429354},
  annote={(Best Paper Award)}
}


@inproceedings{parveen2018hielm,
  title={HielM: Highly Flexible In-Memory Computing using STT MRAM},
  author={Parveen, Farhana and He, Zhezhi and Angizi, Shaahin and Fan, Deliang},
  booktitle={2018 23rd Asia and South Pacific Design Automation Conference (ASP-DAC)},
  pages={361--366},
  year={2018},
  organization={IEEE},
  keywords  = {conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8297350}
}

@inproceedings{angizi2018imce,
  title={IMCE: Energy-Efficient Bit-wise In-memory Convolution Engine for Deep Neural Network},
  author={Angizi, Shaahin and He, Zhezhi and Parveen, Farhana and Fan, Deliang},
  booktitle={Proceedings of the 23rd Asia and South Pacific Design Automation Conference},
  pages={111--116},
  year={2018},
  organization={IEEE Press},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/10.5555/3201607.3201631}
}

@article{parveen2018imcs2,
  title={IMCS2: Novel Device-to-Architecture Co-Design for Low-Power In-Memory Computing Platform Using Coterminous Spin Switch},
  author={Parveen, Farhana and Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  journal={IEEE Transactions on Magnetics},
  volume={54},
  number={7},
  pages={1--14},
  year={2018},
  publisher={IEEE},
  keywords  = {journal},
  link = {https://ieeexplore.ieee.org/abstract/document/8344511}
}

@inproceedings{angizi2018leveraging,
  title={Leveraging Spintronic Devices for Efficient Approximate Logic and Stochastic Neural Networks},
  author={Angizi, Shaahin and He, Zhezhi and Bai, Yu and Han, Jie and Lin, Mingjie and DeMara, Ronald F and Fan, Deliang},
  booktitle={Proceedings of the 2018 on Great Lakes Symposium on VLSI},
  pages={397--402},
  year={2018},
  organization={ACM},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/10.1145/3194554.3194618}
}

@article{he2018exploring,
  title={Exploring A SOT-MRAM based In-Memory Computing for Data Processing},
  author={He, Zhezhi and Zhang, Yang and Angizi, Shaahin and Gong, Boqing and Fan, Deliang},
  journal={IEEE Transactions on Multi-Scale Computing Systems},
  year={2018},
  publisher={IEEE},
  keywords  = {journal},
  link = {https://ieeexplore.ieee.org/abstract/document/8360447}
}

@inproceedings{angizi2018cmp,
  title={CMP-PIM: An Energy-Efficient Comparator-based Processing-in-Memory Neural Network Accelerator},
  author={He=, Zhezhi and Angizi=, Shaahin and Rakin, Adnan Siraj and Fan, Deliang},
  booktitle={Proceedings of the 55th Annual Design Automation Conference (DAC)},
  pages={105},
  year={2018},
  organization={ACM},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/10.1145/3195970.3196009}
}

@inproceedings{angizi2018pima,
  title={PIMA-logic: A Novel Processing-in-Memory Architecture for Highly Flexible and Energy-Efficient Logic Computation},
  author={Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={Proceedings of the 55th Annual Design Automation Conference (DAC)},
  pages={162},
  year={2018},
  organization={ACM},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/10.1145/3195970.3196092}
}



@article{he2017energy,
  title={Energy Efficient Reconfigurable Threshold Logic Circuit with Spintronic Devices},
  author={He, Zhezhi and Fan, Deliang},
  journal={IEEE Transactions on Emerging Topics in Computing (TETC)},
  volume={5},
  number={2},
  pages={223--237},
  year={2017},
  publisher={IEEE},
  keywords={journal},
  link={https://ieeexplore.ieee.org/abstract/document/7779139}
}

@article{he2017current,
  title={Current-induced Dynamics of Multiple Skyrmions with Domain-wall Pair and Skyrmion-based Majority Gate Design},
  author={He, Zhezhi and Angizi, Shaahin and Fan, Deliang},
  journal={IEEE Magnetics Letters},
  volume={8},
  pages={1--5},
  year={2017},
  publisher={IEEE},
  keywords={journal},
  link={https://ieeexplore.ieee.org/abstract/document/7890449}
}


@inproceedings{angizi2017composite,
  title={Composite Spintronic Accuracy-configurable Adder for Low Power Digital Signal Processing},
  author={Angizi, Shaahin and He, Zhezhi and DeMara, Ronald F and Fan, Deliang},
  booktitle={2017 18th International Symposium on Quality Electronic Design (ISQED)},
  pages={391--396},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/7918347}
}

@inproceedings{he2017tunable,
  title={A Tunable Magnetic Skyrmion Neuron Cluster for Energy Efficient Artificial Neural Network},
  author={He, Zhezhi and Fan, Deliang},
  booktitle={Design, Automation \& Test in Europe Conference \& Exhibition (DATE)},
  pages={350--355},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/7927015}
}


@article{he2017developing,
  title={Developing All-Skyrmion Spiking Neural Network},
  author={He, Zhezhi and Fan, Deliang},
  journal={Neuromorphic Computing Symposium (NCS)},
  year={2017},
  keywords={conference},
  preprint={https://arxiv.org/pdf/1705.02995.pdf}
}

@inproceedings{he2017leveraging,
  title={Leveraging Dual-mode Magnetic Crossbar for Ultra-low Energy In-memory Data Encryption},
  author={He, Zhezhi and Angizi, Shaahin and Parveen, Farhana and Fan, Deliang},
  booktitle={Proceedings of the on Great Lakes Symposium on VLSI 2017 (GLSVLSI)},
  pages={83--88},
  year={2017},
  organization={ACM},
  keywords={conference},
  link={https://dl.acm.org/doi/10.1145/3060403.3060460}
}

@inproceedings{angizi2017energy,
  title={Energy Efficient In-memory Computing Platform based on 4-terminal Spin Hall Effect-driven Domain Wall Motion Devices},
  author={Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={Proceedings of the on Great Lakes Symposium on VLSI (GLSVLSI)},
  pages={77--82},
  year={2017},
  organization={ACM},
  keywords={conference},
  link={https://dl.acm.org/doi/10.1145/3060403.3060459}
}

@inproceedings{angizi2017rimpa,
  title={Rimpa: A new Reconfigurable Dual-mode In-memory Processing Architecture with Spin Hall Effect-driven Domain Wall Motion Device},
  author={Angizi, Shaahin and He, Zhezhi and Parveen, Farhana and Fan, Deliang},
  booktitle={2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={45--50},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/7987493}
}

@inproceedings{parveen2017hybrid2,
  title={Hybrid Polymorphic Logic Gate with 5-terminal Magnetic Domain Wall Motion Device},
  author={Parveen, Farhana and He, Zhezhi and Angizi, Shaahin and Fan, Deliang},
  booktitle={IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={152--157},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/7987511},
  annote={(Best Paper Award)}
}

@inproceedings{fan2017memory,
  title={In-memory Computing with Spintronic Devices},
  author={Fan, Deliang and Angizi, Shaahin and He, Zhezhi},
  booktitle={IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={683--688},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/7987602}
}

@inproceedings{parveen2017low,
  title={Low Power In-memory Computing based on Dual-mode SOT-MRAM},
  author={Parveen, Farhana and Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={2017 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED)},
  pages={1--6},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/8009200}
}

@inproceedings{parveen2017hybrid1,
  title={Hybrid Polymorphic Logic Gate using 6 Terminal Magnetic Domain Wall Motion Device},
  author={Parveen, Farhana and Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={IEEE International Symposium on Circuits and Systems (ISCAS)},
  pages={1--4},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/8050921}
}

@inproceedings{fan2017leveraging,
  title={Leveraging Spintronic Devices for Ultra-low Power In-memory Computing: Logic and Neural Network},
  author={Fan, Deliang and He, Zhezhi and Angizi, Shaahin},
  booktitle={IEEE 60th International Midwest Symposium on Circuits and Systems (MWSCAS)},
  pages={1109--1112},
  year={2017},
  organization={IEEE},
  keywords  = {conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8053122}
}

@inproceedings{he2017high,
  title={High Performance and Energy-efficient In-memory Computing Architecture Based on SOT-MRAM},
  author={He, Zhezhi and Angizi, Shaahin and Parveen, Farhana and Fan, Deliang},
  booktitle={IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH)},
  pages={97--102},
  year={2017},
  organization={IEEE},
  keywords  = {conference},
  link ={https://ieeexplore.ieee.org/abstract/document/8053122}
}

@article{angizi2018design,
  title={Design and Evaluation of a Spintronic In-Memory Processing Platform for Nonvolatile Data Encryption},
  author={Angizi, Shaahin and He, Zhezhi and Bagherzadeh, Nader and Fan, Deliang},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (ICCAD)},
  volume={37},
  number={9},
  pages={1788--1801},
  year={2018},
  publisher={IEEE},
  keywords  = {journal},
  link = {https://ieeexplore.ieee.org/abstract/document/8053122}
}

@inproceedings{he2017exploring,
  title={Exploring STT-MRAM based In-memory Computing Paradigm with Application of Image Edge Extraction},
  author={He, Zhezhi and Angizi, Shaahin and Fan, Deliang},
  booktitle={2017 IEEE International Conference on Computer Design (ICCD)},
  pages={439--446},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8119251}
}

@inproceedings{he2016low,
  title={A Low Power Current-mode Flash ADC with Spin Hall Effect Based Multi-threshold Comparator},
  author={He, Zhezhi and Fan, Deliang},
  booktitle={Proceedings of the 2016 International Symposium on Low Power Electronics and Design (ISLPED)},
  pages={314--319},
  year={2016},
  organization={ACM},
  keywords={conference},
  link={https://dl.acm.org/doi/10.1145/2934583.2934642}
}





