@inproceedings{su2024ICANN,
  title={Obtaining Optimal Spiking Neural Network in Sequence Learning via CRNN-SNN Conversion},
  author={Su*, Jiahao and  You*, Kang and He<sup>&#9993</sup>, Zhezhi},
  booktitle={Proceedings of 33rd International Conference on Artificial Neural Networks (ICANN)},
  keywords={conference},
  year={2024}
  }

@inproceedings{you2024ICML,
  title={SpikeZIP-TF: Conversion is All You Need for Transformer-based SNN},
  author={You*=, Kang and Xu*=, Zekaiu and Nie*, Chen and Deng, Zhijie and Guo, Qinghai and Wang, Xiang and He<sup>&#9993</sup>, Zhezhi},
  booktitle={Proceedings of Forty-First International conference on Machine Learning (ICML)},
  keywords={conference},
  year={2024},
  code={https://github.com/Intelligent-Computing-Research-Group/SpikeZIP-TF},
  preprint={https://arxiv.org/abs/2406.03470}
  }

@inproceedings{deng2024ICML,
  title={CLLMs: Consistency Large Language Models},
  author={Kou, Siqi and Hu, Lanxiang and He, Zhezhi and Deng, Zhijie and Zhang, Hao},
  booktitle={Proceedings of Forty-First International conference on Machine Learning (ICML) },
  keywords={conference},
  year={2024},
  code={https://github.com/hao-ai-lab/Consistency_LLM},
  preprint={https://arxiv.org/abs/2403.00835}
  }

  Siqi Kou, Lanxiang Hu, Zhezhi He, Zhijie Deng, Hao Zhang

@inproceedings{qian2024ISEDA,
  title={ERL-LS: Accelerating the Optimization of Logic Synthesis with Evolutionary Reinforcement Learning},
  author={Lv*, Chenyang and Zhang*, Boning and Qian, Weikang and He<sup>&#9993</sup>, Zhezhi},
  booktitle={Proceedings of International Symposium of Electronic Design Automation (ISEDA) },
  keywords={conference},
  year={2024}
  }


@inproceedings{qian2024date,
  title={An Efficient Logic Operation Scheduler For Minimizing Memory Footprint Of In-memory SIMD Computation},
  author={Qian, Xingyue and He<sup>&#9993</sup>, Zhezhi and Qian<sup>&#9993</sup>, Weikang},
  booktitle={Proceedings of Design, Automation and Test in Europe Conference (DATE)},
  keywords={conference},
  year={2024}
  }

@inproceedings{tang2024pimlc,
  title={PIMLC: Logic Compiler for Bit-serial Based PIM},
  author={Tang*, Chenyu and Nie*, Chen and Qian, Weikang and He<sup>&#9993</sup>, Zhezhi},
  booktitle={Proceedings of Design, Automation and Test in Europe Conference (DATE)},
  keywords={conference},
  year={2024},
  link={https://umji.sjtu.edu.cn/~wkqian/papers/Tang_Nie_Qian_He_PIMLC_Logic_Compiler_for_Bit-Serial-Based_PIM.pdf},
  code={https://github.com/Intelligent-Computing-Research-Group/PIMLC}
  }

@article{xie2023nc,
  title={Monolithic 3D integration of 2D transistors and vertical RRAMs in 1T-4R structure for high-density memory},
  author={Xie=, Maosong and Ji=, Yueyang and Nie*, Chen and Liu, Zuheng and Tang, Alvin and Fan, Shiquan and Liang, Xiaoyao and Jiang, Li and He<sup>&#9993</sup>, Zhezhi and Yang<sup>&#9993</sup>, Rui},
  journal={Nature Communications},
  year={2023},
  keywords  = {journal},
  link = {https://www.nature.com/articles/s41467-023-41736-2},
  doi = {10.1038/s41467-023-41736-2}
}

@inproceedings{lv2023gptls,
  title={GPT-LS: Generative Pre-Trained Transformer with Off-line Reinforcement Learning for Logic Synthesis},
  author={Lv*, Chenyang and Wei*, Ziling and Qian, Weikang and Ye, Junjie and Feng, Chang and He<sup>&#9993</sup>, Zhezhi},
  booktitle={Proceedings of 41st IEEE International Conference on Computer Design (ICCD)},
  keywords={conference},
  year={2023},
  code={https://github.com/Intelligent-Computing-Research-Group/GPT-LS}
  }
@inproceedings{nie2023gim,
  title={GIM: Versatile GNN Acceleration with Reconfigurable Processing-in-Memory},
  author={Nie*, Chen and Chen, Guoyang and Zhang, Weifeng and He<sup>&#9993</sup>, Zhezhi},
  booktitle={Proceedings of 41st IEEE International Conference on Computer Design (ICCD)},
  keywords={conference},
  year={2023},
  award={Best Paper Nomination}
  }

  @inproceedings{xuan2023hyacc,
  title={HyAcc: A Hybrid CAM-MAC RRAM-based Accelerator for Recommendation Model},
  author={Zhang, Xuan and Song, Zhuoran and Li, Xing and He, Zhezhi and Jiang, Li and Jing, Naifeng and Liang, Xiaoyao},
  booktitle={Proceedings of 41st IEEE International Conference on Computer Design (ICCD)},
  keywords={conference},
  year={2023}
  } 
@article{nie2023vspim,
  title={VSPIM: SRAM Processing-in-Memory DNN Acceleration via Vector-Scalar Operations},
  author={Nie*, Chen and Tang*, Chenyu and Lin, Jie and Hu, Huan and Lv*, Chenyang and Cao, Ting and Zhang, Weifeng and Jiang, Li and Liang, Xiaoyao and Qian, Weikang and Sun, Yanan and He<sup>&#9993</sup>, Zhezhi},
  journal={IEEE Transactions on Computers (TC)},
  year={2023},
  keywords  = {journal},
  link = {https://ieeexplore.ieee.org/abstract/document/10151688},
  doi = {https://doi.org/10.1109/TC.2023.3285095}
}
@inproceedings{nie2023xmg,
  title={XMG-GPPIC: Efficient and Robust General-Purpose Processing-in-Cache with XOR-Majority-Graph},
  author={Nie*, Chen and Cai, Xianjue and Lv*, Chenyang and Huang, Chen and Qian<sup>&#9993</sup>, Weikang and He<sup>&#9993</sup>, Zhezhi},
  booktitle={Proceedings of the 2023 on Great Lakes Symposium on VLSI (GLSVLSI'2023)},
  keywords={conference},
  year={2023},
  link={https://dl.acm.org/doi/abs/10.1145/3583781.3590288},
  doi={10.1145/3583781.3590288}
  }
@inproceedings{yang2023pimpr,
  title={PIMPR: PIM-based Personalized Recommendation with Heterogeneous Memory Hierarchy},
  author={Yang, Tao and Ma, Hui and Zhao, Yilong and Liu, Fangxin and He, Zhezhi and Sun, Xiaoli and Jiang, Li},
  booktitle={2023 Design, Automation \& Test in Europe Conference \& Exhibition (DATE'2023)},
  pages={1--6},
  year={2023},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/10137249/}
}

@article{li2023model,
  title={Model Extraction Attacks on Split Federated Learning},
  author={Li, Jingtao and Rakin, Adnan Siraj and Chen, Xing and Yang, Li and He, Zhezhi and Fan, Deliang and Chakrabarti, Chaitali},
  journal={arXiv preprint arXiv:2303.08581},
  year={2023}
}


@inproceedings{gong2022n3h,
  title={N\textsuperscript{3}H-Core: Neuron-designed Neural Network Accelerator via FPGA-based Heterogeneous Computing Cores},
  author={Gong*=, Yu and Xu*=, Zhihan and He<sup>&#9993</sup>, Zhezhi and Zhang, Weifeng and Tu, Xiaobing and Liang, Xiaoyao and Jiang<sup>&#9993</sup>, Li},
  booktitle={Proceedings of the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA'22)},
  keywords={conference},
  year={2022},
  preprint={https://arxiv.org/abs/2112.08193},
  code={https://github.com/elliothe/N3H_Core}
}


@inproceedings{tang2022NAS,
  title={HAWIS: Hardware-Aware Automated WIdth Search for Accurate,  Energy-Efficient and Robust Binary Neural Network on ReRAM Dot-Product Engine },
  author={Tang*, Qidong and He<sup>&#9993</sup>, Zhezhi and Liu, Fangxin and Wang, Zongwu and Zhou, Yiyuan and Zhang, Yinghuan and Jiang<sup>&#9993</sup>, Li},
  booktitle={Proceedings of 27th Asia and South Pacific Design Automation Conference (ASP-DAC'22)},
  keywords={conference},
  year={2022},
  code={https://github.com/Intelligent-Computing-Research-Group/HAWIS/},
  slides={https://github.com/Intelligent-Computing-Research-Group/HAWIS/blob/master/%5BASPDAC-22%5DHAWIS_slides.pdf},
  preprint={https://github.com/Intelligent-Computing-Research-Group/HAWIS/blob/master/%5BASPDAC-22%5DHAWIS_preprint.pdf}
}

@inproceedings{wang2022SWT,
  title={Self-Terminating Writing of Multi-Level Cell ReRAM for Efficient Neuromorphic Computing},
  author={Wang*, Zongwu and He<sup>&#9993</sup>, Zhezhi and Yang, Rui and Fan, Shiquan and Lin, Jie and Jia, Yueyang and Yuan, Chenxi and Tang, Qidong and Jiang<sup>&#9993</sup>, Li},
  booktitle={Proceedings of IEEE Design, Automation and Test in Europe Conference (DATE'22)},
  keywords={conference},
  year={2022},
  preprint={https://github.com/Intelligent-Computing-Research-Group/DATE_22_STW/blob/main/preprint.pdf},
  award={Best Paper Award}
}

@inproceedings{li2022ressfl,
title={ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning},
author={Li, Jingtao and Rakin, Adnan Siraj and Chen, Xing and He, Zhezhi and Fan, Deliang and Chakrabarti, Chaitali},
booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR'22)},
year={2022}
}


@article{yang2022dtatrans,
title={DTATrans: Leveraging Dynamic Token-based Quantization with Accuracy Compensation Mechanism for Efficient Transformer Architecture},
author={Yang, Tao and Ma, Hui and Li, Xiaoling and Liu, Fangxin and Zhao, Yilong and He, Zhezhi and Jiang, Li},
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD'22)},
year={2022},
publisher={IEEE}
}

@article{liu2022sobs,
title={SoBS-X: Squeeze-Out Bit Sparsity for ReRAM-Crossbar-Based Neural Network Accelerator},
author={Liu, Fangxin and Wang, Zongwu and Chen, Yongbiao and He, Zhezhi and Yang, Tao and Liang, Xiaoyao and Jiang, Li},
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD'22)},
year={2022},
publisher={IEEE}
}

@inproceedings{nie2022cross,
title={Cross-layer Designs against Non-ideal Effects in ReRAM-based Processing-in-Memory System},
author={Nie, Chen and Wang, Zongwu and Tang, Qidong and Lv, Chenyang and Jiang, Li and He, Zhezhi},
booktitle={2022 23rd International Symposium on Quality Electronic Design (ISQED'22)},
pages={1--6},
year={2022},
organization={IEEE}
}

@inproceedings{liu2022sato,
title={SATO: spiking neural network acceleration via temporal-oriented dataflow and architecture},
author={Liu, Fangxin and Zhao, Wenbo and Wang, Zongwu and Chen, Yongbiao and Yang, Tao and He, Zhezhi and Yang, Xiaokang and Jiang, Li},
booktitle={Proceedings of the 59th ACM/IEEE Design Automation Conference (DAC'22)},
pages={1105--1110},
year={2022}
}

@inproceedings{liu2022ebsp,
title={EBSP: evolving bit sparsity patterns for hardware-friendly inference of quantized deep neural networks},
author={Liu, Fangxin and Zhao, Wenbo and Wang, Zongwu and Chen, Yongbiao and He, Zhezhi and Jing, Naifeng and Liang, Xiaoyao and Jiang, Li},
booktitle={Proceedings of the 59th ACM/IEEE Design Automation Conference (DAC'22)},
pages={259--264},
year={2022}
}

@inproceedings{liu2022pim,
title={PIM-DH: ReRAM-based processing-in-memory architecture for deep hashing acceleration},
author={Liu, Fangxin and Zhao, Wenbo and Chen, Yongbiao and Wang, Zongwu and He, Zhezhi and Yang, Rui and Tang, Qidong and Yang, Tao and Zhuo, Cheng and Jiang, Li},
booktitle={Proceedings of the 59th ACM/IEEE Design Automation Conference (DAC'22)},
pages={1087--1092},
year={2022}
}



@inproceedings{yang2022dtqatten,
title={DTQAtten: Leveraging Dynamic Token-based Quantization for Efficient Attention Architecture},
author={Yang, Tao and Li, Dongyue and Song, Zhuoran and Zhao, Yilong and Liu, Fangxin and Wang, Zongwu and He, Zhezhi and Jiang, Li},
booktitle={(DATE-22) 2022 Design, Automation \& Test in Europe Conference \& Exhibition (DATE'22)},
pages={700--705},
year={2022},
organization={IEEE}
}


@inproceedings{liu2021sme,
  title={SME: ReRAM-based Sparse-Multiplication-Engine to Squeeze-Out Bit Sparsity of Neural Network},
  author={Liu, Fangxin and Zhao, Wenbo and Zhao, Yilong and Wang, Zongwu and Yang, Tao and He, Zhezhi and Jing, Naifeng and Liang, Xiaoyao and Jiang, Li},
  booktitle={IEEE International Conference on Computer Design (ICCD'21)},
  year={2021},
  preprint={https://arxiv.org/abs/2103.01705},
  code={https://github.com/MXHX7199/ICCV_2021_AFP}
}

@inproceedings{liu2021ICCAD,
  title={Bit-Transformer: Transforming Bit-level Sparsity into Higher Preformance in ReRAM-based Accelerator},
  author={Liu, Fangxin and Zhao, Wenbo and He, Zhezhi and Wang, Zongwu and Zhao, Yilong and Chen, Yongbiao and Jiang, Li},
  booktitle={International Conference On Computer Aided Design (ICCAD'21)},
  year={2021}
}



@inproceedings{li2021adaptivegcn,
  title={AdaptiveGCN: Efficient GCN Through Adaptively Sparsifying Graphs},
  author={Li*, Dongyue and Yang, Tao and Du, Lun and He<sup>&#9993</sup>, Zhezhi and Jiang<sup>&#9993</sup>, Li},
  booktitle={Proceedings of the 30th ACM International Conference on Information \& Knowledge Management (CIKM'21)},
  pages={3206--3210},
  year={2021},
  doi={10.1145/3459637},
  keywords={conference},
  link={https://dl.acm.org/doi/abs/10.1145/3459637.3482049}
}


@inproceedings{li2021neurobfuscator,
  title={NeurObfuscator: A Full-stack Obfuscation Tool to Mitigate Neural Architecture Stealing},
  author={Li, Jingtao and He, Zhezhi and Rakin, Adnan Siraj and Fan, Deliang and Chakrabarti, Chaitali},
  booktitle={IEEE International Symposium on Hardware Oriented Security and Trust (HOST'21)},
  year={2021},
  preprint={https://arxiv.org/pdf/2107.09789.pdf}
}


@inproceedings{liu2021ICCV,
title={Improving Neural Network Efficiency via Post-training Quantization with Adaptive Floating-Point},
author={Liu, Fangxin and Zhao, Wenbo and He, Zhezhi and Wang, Yanzhi and Wang, Zongwu and Dai, Changzhi and Liang, Xiaoyao and Jiang, Li},
booktitle={International Conference on Computer Vision (ICCV'21)},
year={2021},
link={https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Improving_Neural_Network_Efficiency_via_Post-Training_Quantization_With_Adaptive_Floating-Point_ICCV_2021_paper.html}
}


@inproceedings{lin2021metagater,
  title={MetaGater: Fast Learning of Conditional Channel Gated Networks via Federated Meta-Learning},
  author={Lin, Sen and Yang, Li and He, Zhezhi and Fan, Deliang and Zhang, Junshan},
  booktitle={IEEE 18th International Conference on Mobile Ad Hoc and Smart Systems (MASS'21)},
  year={2021},
  preprint={https://arxiv.org/abs/2011.12511}
}


@inproceedings{he2021HRAM,
  title={Energy-Efficient Hybrid-RAM with Hybrid Bit-Serial based VMM Support},
  author={Nie*, Chen and Lin, Jie and Hu, Huan and Jiang, Li and Liang, Xiaoyao and He<sup>&#9993</sup>, Zhezhi},
  booktitle={Proceedings of Great Lakes Symposium on VLSI 2021 (GLSVLSI'21)},
  year={2021},
  organization={ACM},
  keywords={conference},
  link={https://dl.acm.org/doi/abs/10.1145/3453688.3461528}
}

@inproceedings{zhao2021re2pim,
  title={Re2PIM: A Reconfigurable ReRAM-Based PIM Design for Variable-Sized Vector-Matrix Multiplication},
  author={Zhao, Yilong and He, Zhezhi and Jing, Naifeng and Liang, Xiaoyao and Jiang, Li},
  booktitle={Proceedings of the 2021 on Great Lakes Symposium on VLSI (GLSVLSI'21)},
  pages={15--20},
  year={2021},
  keywords={conference},
  link={https://dl.acm.org/doi/abs/10.1145/3453688.3461494}
}

@inproceedings{song2021reram,
  title={ReRAM-Sharing: Fine-Grained Weight Sharing for ReRAM-Based Deep Neural Network Accelerator},
  author={Song, Zhuoran and Li, Dongyue and He, Zhezhi and Liang, Xiaoyao and Jiang, Li},
  booktitle={2021 IEEE International Symposium on Circuits and Systems (ISCAS)},
  pages={1--5},
  year={2021},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/9401155}
}

@inproceedings{he2021DAC,
  title={PIMGCN: A ReRAM-based PIM Design for Graph Convolutional Network Acceleration},
  author={Yang, Tao and Li, Dongyue and Han, Yibo and Zhao, Yilong and Liu, Fangxin and Liang, Xiaoyao and He, Zhezhi and Jiang, Li},
  booktitle={Proceeding of Design Automation Conference (DAC'21)},
  year={2021},
  organization={ACM},
  keywords  = {conference}
}



@article{9323041,  
  author={Sun, Yanan and Ma, Chang and Li, Zhi and Zhao, Yilong and Jiang, jiachen and  Qian, weikang and Yang, Rui and He, Zhezhi and  Jiang, Li},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)}, 
  title={Unary Coding and Variation-Aware Optimal Mapping Scheme for Reliable ReRAM-based Neuromorphic Computing},   
  year={2021},
  pages={1-1},  
  doi={10.1109/TCAD.2021.3051856},
  keywords={journal},
  organization={IEEE},
  link = {https://ieeexplore.ieee.org/document/9323041}
  }

@inproceedings{he2021ELF,
  title={Elf: Accelerate High-resolution Mobile Deep Vision with Content-aware Parallel Offloading},
  author={Zhang, Wuyang and He, Zhezhi and Liu, Luyang and Jia, Zhenhua and Liu, Yunxin and Gruteser, Marco and Raychaudhuri, Dipankar and Zhang, Yanyong},
  booktitle={27th Annual International Conference on Mobile Computing and Networking (MobiCom'21)},
  year={2021},
  organization={ACM},
  doi={10.1145/3447993.3448628},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/abs/10.1145/3447993.3448628}
}


@inproceedings{he2021RADAR,
  title={RADAR: Run-time Adversarial Weight Attack Detection and Accuracy Recovery},
  author={Li, Jingtao and Rakin, Adnan Siraj and He, Zhezhi and Fan, Deliang and Chakrabarti, Chaitali},
  booktitle={Design, Automation and Test in Europe Conference (DATE'21)},
  year={2021},
  organization={IEEE},
  keywords  = {conference}
}


@inproceedings{he2020SOCC,
  title={Processing-In-Memory Accelerator for Dynamic Neural Network with Run-Time Tuning of Accuracy, Power and Latency},
  author={Yang, Li and He, Zhezhi and Angizi, Shaahin and Fan, Deliang},
  booktitle={33rd IEEE International System-on-Chip Conference (SOCC)},
  year={2020},
  organization={IEEE},
  keywords  = {conference}
}


@article{yang2020progressive,
  title={A Progressive Sub-Network Searching Framework for Dynamic Inference},
  author={Yang, Li and He, Zhezhi and Cao, Yu and Fan, Deliang},
  journal={arXiv preprint arXiv:2009.05681},
  year={2020},
  keywords  = {archive},
  preprint = {https://arxiv.org/pdf/2009.05681.pdf}
}


@article{yang2020ksm,
  title={KSM: Fast Multiple Task Adaption via Kernel-wise Soft Mask Learning},
  author={Yang, Li and He, Zhezhi and Zhang, Junshan and Fan, Deliang},
  journal={Conference on Computer Vision and Pattern Recognition (CVPR'21)},
  year={2021},
  keywords  = {conference},
  annote={(Accepted)},
  preprint={https://arxiv.org/pdf/2009.05668.pdf}
}

@article{rakin2020t,
  title={T-BFA: Targeted Bit-Flip Adversarial Weight Attack},
  author={Rakin, Adnan Siraj and He, Zhezhi and Li, Jingtao and Yao, Fan and Chakrabarti, Chaitali and Fan, Deliang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  year={2021},
  annote={(Accepted)},
  preprint={https://arxiv.org/pdf/2007.12336.pdf}
}


@article{Durjoy2020EDL,
  title={2D MoS2 Based Threshold Switching Memristor For Artificial Neuron},
  author={Dev, Durjoy and Krishnaprasad, Adithi and Shawkat, Mashiyat and He, Zhezhi and Das, Sonali and Chung, Hee-Suk and Fan, Deliang and Jung, Yeonwoong and Roy, Tania},
  abstract={In this work, we use a two-terminal 2D MoS2-based memristive device to emulate an artificial neuron. The Au/MoS2/Ag device exhibits volatile resistance switching characteristics with a low threshold voltage and a high ON-OFF ratio of 106, originating from an Ag diffusion-based filamentary process. The leaky integrate-and-fire neuron implemented with this device successfully emulates the key characteristics of a biological neuron.},
  journal={IEEE Electron Device Letters (EDL)},
  year={2020},
  keywords={journal},
  link={https://ieeexplore.ieee.org/document/9069258}
}


@article{he2020defend,
  title={Defending and Harnessing the Bit-Flip based Adversarial Weight Attack},
  author={He, Zhezhi and Rakin, Adnan Siraj and Li, Jingtao and Chakrabarti, Chaitali and Fan, Deliang},
  journal={Conference on Computer Vision and Pattern Recognition (CVPR'20)},
  abstract={Recently, a new paradigm of the adversarial attack on the quantized neural network weights has attracted great attention, namely, the Bit-Flip based adversarial weight attack, aka. Bit-Flip Attack (BFA). BFA has shown extraordinary attacking ability, where the adversary can malfunction a quantized Deep Neural Network (DNN) as a random guess, through malicious bit-flips on a small set of vulnerable weight bits (e.g., 13 out of 93 millions bits of 8-bit quantized ResNet-18). However, there are no effective defensive methods to enhance the fault-tolerance capability of DNN against such BFA. In this work, we conduct comprehensive investigations on BFA and propose to leverage binarizationaware training and its relaxation – piece-wise clustering as simple and effective countermeasures to BFA. The experiments show that, for BFA to achieve the identical prediction accuracy degradation (e.g., below 11\% on CIFAR-10), it requires 19.3× and 480.1× more effective malicious bitflips on ResNet-20 and VGG-11 respectively, compared to defend-free counterparts.},
  year={2020},
  keywords={conference},
  preprint={https://dfan.engineering.asu.edu/wp-content/uploads/2020/04/CVPR2020_defense.pdf},
  link={https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Defending_and_Harnessing_the_Bit-Flip_Based_Adversarial_Weight_Attack_CVPR_2020_paper.pdf},
  code={https://github.com/elliothe/BFA},
  annote={(Accepted)}
}

@article{rakin2019tbt,
  title={TBT: Targeted Neural Network Attack with Bit Trojan},
  author={Rakin, Adnan Siraj and He, Zhezhi and Fan, Deliang},
  journal={Conference on Computer Vision and Pattern Recognition (CVPR'20)},
  year={2020},
  keywords={conference},
  annote={(Accepted)},
  link={https://openaccess.thecvf.com/content_CVPR_2020/papers/Rakin_TBT_Targeted_Neural_Network_Attack_With_Bit_Trojan_CVPR_2020_paper.pdf},
  code={https://github.com/adnansirajrakin/TBT-2020},
  preprint={https://arxiv.org/pdf/1909.05193.pdf}
}

@article{yang2020nonuniform,
  title={Non-uniform DNN Structured Subnets Sampling for Dynamic Inference},
  author={Yang, Li and He, Zhezhi and Fan, Deliang},
  journal={57th Design Automation Conference (DAC'20)},
  year={2020},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/9218736/}
}

@article{li2020defend,
  title={Defending Bit-Flip Attack through DNN Weight Reconstruction},
  author={Li, Jingtao and Rakin, Adnan Siraj and Xiong, Yan and Chang, Liangliang and He, Zhezhi and Fan, Deliang and Chakrabarti, Chaitali},
  journal={57th Design Automation Conference (DAC)},
  year={2020},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/9218665}
}

@article{he2021tnnls,
  title={Non-Structured DNN Weight Pruning--Is It Beneficial in Any Platform?},
  author={Ma, Xiaolong and Lin, Sheng and Ye, Shaokai and He, Zhezhi and Zhang, Linfeng and Yuan, Geng and Huat Tan, Sia and Li, Zhengang and Fan, Deliang and Qian, Xuehai and others},
  journal={IEEE Transactions on Neural Networks and Learning Systems (TNNLS)},
  publisher={IEEE},
  year={2021},
  keywords={journal},
  doi={10.1109/TNNLS.2021.3063265},
  preprint={https://www.researchgate.net/profile/Zhezhi_He/publication/334248569_Non-structured_DNN_Weight_Pruning_Considered_Harmful/links/5e8f8a7e4585150839ceaa72/Non-structured-DNN-Weight-Pruning-Considered-Harmful.pdf},
  link={https://ieeexplore.ieee.org/abstract/document/9381660}
}



@article{yang2019harmonious,
  title={Harmonious Coexistence of Structured Weight Pruning and Ternarization for Deep Neural Networks},
  author={Yang, Li and He, Zhezhi and Fan, Deliang},
  journal={Thirty-third AAAI Conference on Artificial Intelligence (AAAI'20)},
  abstract={Deep convolutional neural network (DNN) has demonstrated phenomenal success and been widely used in many computer vision tasks. However, its enormous model size and high computing complexity prohibits its wide deployment into resource limited embedded system, such as FPGA and mGPU. As the two most widely adopted model compression techniques, weight pruning and quantization compress DNN model through introducing weight sparsity (i.e., forcing partial weights as zeros) and quantizing weights into limited bitwidth values, respectively. Although there are works attempting to combine the weight pruning and quantization, we still observe disharmony between weight pruning and quantization, especially when more aggressive compression schemes (e.g., Structured pruning and low bit-width quantization) are used. In this work, taking FPGA as the test computing platform and Processing Elements (PE) as the basic parallel computing unit, we first propose a PE-wise structured pruning scheme, which introduces weight sparsification with considering of the architecture of PE. In addition, we integrate it with an optimized weight ternarization approach which quantizes weights into ternary values ({−1, 0, +1}), thus converting the dominant convolution operations in DNN from multiplication-and-accumulation (MAC) to addition-only, as well as compressing the original model (from 32-bit floating point to 2-bit ternary representation) by at least 16 times. Then, we investigate and solve the coexistence issue between PE-wise Structured pruning and ternarization, through proposing a Weight Penalty Clipping (WPC) technique with self-adapting threshold. Our experiment shows that the fusion of our proposed techniques can achieve the best state-of-theart ∼ 21× PE-wise structured compression rate with merely 1.74\%/0.94\% (top-1/top-5) accuracy degradation of ResNet18 on ImageNet dataset.},
  year={2020},
  keywords={conference},
  link={https://www.aaai.org/Papers/AAAI/2020GB/AAAI-YangL.9289.pdf},
  annote={(Spotlight)}
}


@article{he2020sparse,
  title={Sparse BD-Net: A Multiplication-less DNN with Sparse Binarized Depth-wise Separable Convolution},
  author={He, Zhezhi and Yang, Li and Angizi, Shaahin and Rakin, Adnan Siraj and Fan, Deliang},
  journal={ACM Journal on Emerging Technologies in Computing Systems (JETC)},
  volume={16},
  number={2},
  pages={1--24},
  year={2020},
  publisher={ACM New York, NY, USA},
  keywords={journal},
  link={https://dl.acm.org/doi/10.1145/3369391}
}


@article{he2020bioinformatics,
  title={Network-based multi-task learning models for biomarker selection and cancer outcome prediction},
  author={Wang, Zhibo and He, Zhezhi and Shah, Milan and Zhang, Teng and Fan, Deliang and Zhang, Wei},
  journal={Oxford academic Bioinformatics},
  abstract={Detecting cancer gene expression and transcriptome changes with mRNA-sequencing or array-based data are important for understanding the molecular mechanisms underlying carcinogenesis and cellular events during cancer progression. In previous studies, the differentially expressed genes were detected across patients in one cancer type. These studies ignored the role of mRNA expression changes in driving tumorigenic mechanisms that are either universal or specific in different tumor types. To address the problem, we introduce two network-based multi-task learning frameworks, NetML and NetSML, to discover common differentially expressed genes shared across different cancer types as well as differentially expressed genes specific to each cancer type. The proposed frameworks consider the common latent gene co-expression modules and gene–sample biclusters underlying the multiple cancer datasets to learn the knowledge crossing different tumor types. Large-scale experiments on simulations and real cancer high-throughput datasets validate that the proposed network-based multi-task learning frameworks perform better sample classification compared with the models without the knowledge sharing across different cancer types. The common and cancer-specific molecular signatures detected by multi-task learning frameworks on The Cancer Genome Atlas ovarian, breast and prostate cancer datasets are correlated with the known marker genes and enriched in cancer-relevant Kyoto Encyclopedia of Genes and Genome pathways and gene ontology terms.},
  year={2019},
  keywords  = {journal},
  link={https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btz809/5613179},
  code={https://github.com/compbiolabucf/NetML}
}


@article{angizi2020hybrid,
  title={Hybrid Spin-CMOS Polymorphic Logic Gate With Application in In-Memory Computing},
  author={Angizi, Shaahin and He, Zhezhi and Chen, An and Fan, Deliang},
  journal={IEEE Transactions on Magnetics},
  volume={56},
  number={2},
  pages={1--15},
  year={2020},
  publisher={IEEE},
  keywords  = {journal},
  link={https://ieeexplore.ieee.org/abstract/document/8956045}
}


@inproceedings{dev2019artificial,
  title={Artificial Neuron using Ag/2D-MoS 2/Au Threshold Switching Memristor},
  author={Dev, Durjoy and Krishnaprasad, Adithi and He, Zhezhi and Das, Sonali and Shawkat, Mashiyat Sumaiya and Manley, Madison and Aina, Olaleye and Fan, Deliang and Jung, Yeonwoong and Roy, Tania},
 abstract={The phenomenal evolution of information and communication drives future technologies towards highly parallel, energy-efficient self-learning systems like the human brain. The limitations of current von Neumann computation systems have paved the way for artificial neural networks (ANN) to meet these criteria. The memristor has become an emerging candidate to realize ANN through emulating biological synapse and neuron behavior. We previously reported an artificial neuron with 2D Mos2 and graphene electrode, but the operating voltage was high, and the output current was low. In this work, we harness threshold switching in Mos2 enabled by Ag electrode, to emulate integration and firing behavior of neuron and demonstrate digit recognition application with these devices. The simple vertical structure of Ag/MoS2/Au threshold switching memristor (TSM), with very low threshold voltage (Vth=0.4−0.5V) , displays the four crucial features of neuron─ all-or-nothing spiking, threshold-driven firing, post firing refractory period and stimulus strength based frequency response.},
  booktitle={Device Research Conference (DRC)},
  pages={193--194},
  year={2019},
  organization={IEEE},
  keywords  = {conference},
  link={https://ieeexplore.ieee.org/abstract/document/9046335}
}


@inproceedings{he2019PBS,
  title={Bit-Flip Attack: Crushing Neural Network with Progressive Bit Search},
  author={He<sup>=</sup>, Zhezhi and Rakin<sup>=</sup>, Adnan Siraj and Fan, Deliang},
  booktitle={International Conference on Computer Vision (ICCV'19)},
  year={2019},
  keywords={conference},
  link={http://openaccess.thecvf.com/content_ICCV_2019/papers/Rakin_Bit-Flip_Attack_Crushing_Neural_Network_With_Progressive_Bit_Search_ICCV_2019_paper.pdf},
  code={https://github.com/elliothe/Neural_Network_Weight_Attack}
}


@inproceedings{angizi2019accelerating,
author={Angizi, Shaahin and He, Zhezhi and Reis, Dayane and Hu, Sharon Xiaobo and Tsai, Wilman and Lin, Shy Jay and Fan, Deliang},
booktitle={2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
title={Accelerating Deep Neural Networks in Processing-in-Memory Platforms: Analog or Digital Approach?},
year={2019},
pages={197-202},
keywords={conference},
link={https://ieeexplore.ieee.org/abstract/document/8839490}
}

@article{he2019parametric,
  title={Parametric Noise Injection: Trainable Randomness to Improve Deep Neural Network Robustness against Adversarial Attack},
  author={He=, Zhezhi and Rakin=, Adnan Siraj and Fan, Deliang},
  journal={Conference on Computer Vision and Pattern (CVPR)},
  year={2019},
  keywords  = {conference},
  link={https://github.com/elliothe/CVPR_2019_PNI/blob/master/CVPR19_PNI.pdf},
  code={https://github.com/elliothe/CVPR_2019_PNI}
}


@article{he2019simultaneously,
  title={Simultaneously Optimizing Weight and Quantizer of Ternary Neural Network using Truncated Gaussian Approximation},
  author={He, Zhezhi and Fan, Deliang},
  journal={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019},
  keywords  = {conference},
  link={http://openaccess.thecvf.com/content_CVPR_2019/html/He_Simultaneously_Optimizing_Weight_and_Quantizer_of_Ternary_Neural_Network_Using_CVPR_2019_paper.html}
}


@article{he2019NIA,
  title={Noise Injection Adaption: End-to-End ReRAM Crossbar Non-ideal Effect Adaption for Neural Network Mapping},
  author={He, Zhezhi and Lin, Jie and Ewetz, Rickard and Yuan, Jiann-Shiun and Fan, Deliang},
  journal={56-th Design Automation Conference (DAC)},
  year={2019},
  publisher={ACM},
  keywords  = {conference},
  link={https://dl.acm.org/doi/10.1145/3316781.3317870},
  code={https://github.com/elliothe/pytorx}
}

@article{he2019optimize,
  title={Optimize Deep Convolutional Neural Network with Ternarized Weights and High Accuracy},
  author={He, Zhezhi and Gong, Boqing and Fan, Deliang},
  journal={IEEE Winter Conference on Applications of Computer Vision (WACV)},
  year={2019},
  keywords  = {conference},
  link={https://ieeexplore.ieee.org/abstract/document/8658565},
  code={https://github.com/elliothe/Ternarized_Neural_Network}
}

@article{he2019BYOLO,
  title={Binarized Depthwise Separable Neural Network for Object Tracking in FPGA},
  author={Yang, Li and He, Zhezhi and Fan, Deliang},
  journal={Great Lakes Symposium on VLSI (GLSVLSI)},
  year={2019},
  keywords = {conference},
  link={https://dl.acm.org/doi/10.1145/3299874.3318034}
}

@article{angizi2019mrima,
  title={MRIMA: An MRAM-based In-Memory Accelerator},
  author={Angizi, Shaahin and He, Zhezhi and Awad, Amro and Fan, Deliang},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  year={2019},
  publisher={IEEE},
  keywords  = {journal},
  link = {https://ieeexplore.ieee.org/abstract/document/8675492}
}

@inproceedings{angizi2019parapim,
  title={ParaPIM: A Parallel Processing-In-Memory Accelerator for Binary-Weight Deep Neural Networks},
  author={Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={Proceedings of the 24th Asia and South Pacific Design Automation Conference (ASP-DAC)},
  pages={127--132},
  year={2019},
  organization={ACM},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/10.1145/3287624.3287644}
}


@inproceedings{angizi2018dima,
  title={DIMA: A Depthwise CNN In-Memory Accelerator},
  author={Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
  pages={1--8},
  year={2018},
  organization={IEEE},
  keywords  = {conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8587671}
}

@inproceedings{rakin2018pim,
  title={PIM-TGAN: A Processing-in-Memory Accelerator for Ternary Generative Adversarial Networks},
  author={Rakin, Adnan Siraj and Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={2018 IEEE 36th International Conference on Computer Design (ICCD)},
  pages={266--273},
  year={2018},
  organization={IEEE},
  keywords  = {conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8615698}
}


@inproceedings{yang2018fully,
  title={A Fully Onchip Binarized Convolutional Neural Network FPGA Impelmentation with Accurate Inference},
  author={Yang, Li and He, Zhezhi and Fan, Deliang},
  booktitle={Proceedings of the International Symposium on Low Power Electronics and Design (ISLPED)},
  pages={50},
  year={2018},
  organization={ACM},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/10.1145/3218603.3218615}
}

@inproceedings{he2018accelerating,
  title={Accelerating Low Bit-Width Deep Convolution Neural Network in MRAM},
  author={He, Zhezhi and Angizi, Shaahin and Fan, Deliang},
  booktitle={2018 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={533--538},
  year={2018},
  organization={IEEE},
  keywords ={conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8429424}
}


@inproceedings{he2018bd,
  title={BD-NET: A Multiplication-Less DNN with Binarized Depthwise Separable Convolution},
  author={He, Zhezhi and Angizi, Shaahin and Rakin, Adnan Siraj and Fan, Deliang},
  booktitle={2018 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={130--135},
  year={2018},
  organization={IEEE},
  keywords  = {conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8429354},
  award={Best Paper Award}
}


@inproceedings{parveen2018hielm,
  title={HielM: Highly Flexible In-Memory Computing using STT MRAM},
  author={Parveen, Farhana and He, Zhezhi and Angizi, Shaahin and Fan, Deliang},
  booktitle={2018 23rd Asia and South Pacific Design Automation Conference (ASP-DAC)},
  pages={361--366},
  year={2018},
  organization={IEEE},
  keywords  = {conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8297350}
}

@inproceedings{angizi2018imce,
  title={IMCE: Energy-Efficient Bit-wise In-memory Convolution Engine for Deep Neural Network},
  author={Angizi, Shaahin and He, Zhezhi and Parveen, Farhana and Fan, Deliang},
  booktitle={Proceedings of the 23rd Asia and South Pacific Design Automation Conference},
  pages={111--116},
  year={2018},
  organization={IEEE Press},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/10.5555/3201607.3201631}
}

@article{parveen2018imcs2,
  title={IMCS2: Novel Device-to-Architecture Co-Design for Low-Power In-Memory Computing Platform Using Coterminous Spin Switch},
  author={Parveen, Farhana and Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  journal={IEEE Transactions on Magnetics},
  volume={54},
  number={7},
  pages={1--14},
  year={2018},
  publisher={IEEE},
  keywords  = {journal},
  link = {https://ieeexplore.ieee.org/abstract/document/8344511}
}

@inproceedings{angizi2018leveraging,
  title={Leveraging Spintronic Devices for Efficient Approximate Logic and Stochastic Neural Networks},
  author={Angizi, Shaahin and He, Zhezhi and Bai, Yu and Han, Jie and Lin, Mingjie and DeMara, Ronald F and Fan, Deliang},
  booktitle={Proceedings of the 2018 on Great Lakes Symposium on VLSI},
  pages={397--402},
  year={2018},
  organization={ACM},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/10.1145/3194554.3194618}
}

@article{he2018exploring,
  title={Exploring A SOT-MRAM based In-Memory Computing for Data Processing},
  author={He, Zhezhi and Zhang, Yang and Angizi, Shaahin and Gong, Boqing and Fan, Deliang},
  journal={IEEE Transactions on Multi-Scale Computing Systems},
  year={2018},
  publisher={IEEE},
  keywords  = {journal},
  link = {https://ieeexplore.ieee.org/abstract/document/8360447}
}

@inproceedings{angizi2018cmp,
  title={CMP-PIM: An Energy-Efficient Comparator-based Processing-in-Memory Neural Network Accelerator},
  author={He=, Zhezhi and Angizi=, Shaahin and Rakin, Adnan Siraj and Fan, Deliang},
  booktitle={Proceedings of the 55th Annual Design Automation Conference (DAC)},
  pages={105},
  year={2018},
  organization={ACM},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/10.1145/3195970.3196009}
}

@inproceedings{angizi2018pima,
  title={PIMA-logic: A Novel Processing-in-Memory Architecture for Highly Flexible and Energy-Efficient Logic Computation},
  author={Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={Proceedings of the 55th Annual Design Automation Conference (DAC)},
  pages={162},
  year={2018},
  organization={ACM},
  keywords  = {conference},
  link = {https://dl.acm.org/doi/10.1145/3195970.3196092}
}



@article{he2017energy,
  title={Energy Efficient Reconfigurable Threshold Logic Circuit with Spintronic Devices},
  author={He, Zhezhi and Fan, Deliang},
  journal={IEEE Transactions on Emerging Topics in Computing (TETC)},
  volume={5},
  number={2},
  pages={223--237},
  year={2017},
  publisher={IEEE},
  keywords={journal},
  link={https://ieeexplore.ieee.org/abstract/document/7779139}
}

@article{he2017current,
  title={Current-induced Dynamics of Multiple Skyrmions with Domain-wall Pair and Skyrmion-based Majority Gate Design},
  author={He, Zhezhi and Angizi, Shaahin and Fan, Deliang},
  journal={IEEE Magnetics Letters},
  volume={8},
  pages={1--5},
  year={2017},
  publisher={IEEE},
  keywords={journal},
  link={https://ieeexplore.ieee.org/abstract/document/7890449}
}


@inproceedings{angizi2017composite,
  title={Composite Spintronic Accuracy-configurable Adder for Low Power Digital Signal Processing},
  author={Angizi, Shaahin and He, Zhezhi and DeMara, Ronald F and Fan, Deliang},
  booktitle={2017 18th International Symposium on Quality Electronic Design (ISQED)},
  pages={391--396},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/7918347}
}

@inproceedings{he2017tunable,
  title={A Tunable Magnetic Skyrmion Neuron Cluster for Energy Efficient Artificial Neural Network},
  author={He, Zhezhi and Fan, Deliang},
  booktitle={Design, Automation \& Test in Europe Conference \& Exhibition (DATE)},
  pages={350--355},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/7927015}
}


@article{he2017developing,
  title={Developing All-Skyrmion Spiking Neural Network},
  author={He, Zhezhi and Fan, Deliang},
  journal={Neuromorphic Computing Symposium (NCS)},
  year={2017},
  keywords={conference},
  preprint={https://arxiv.org/pdf/1705.02995.pdf}
}

@inproceedings{he2017leveraging,
  title={Leveraging Dual-mode Magnetic Crossbar for Ultra-low Energy In-memory Data Encryption},
  author={He, Zhezhi and Angizi, Shaahin and Parveen, Farhana and Fan, Deliang},
  booktitle={Proceedings of the on Great Lakes Symposium on VLSI 2017 (GLSVLSI)},
  pages={83--88},
  year={2017},
  organization={ACM},
  keywords={conference},
  link={https://dl.acm.org/doi/10.1145/3060403.3060460}
}

@inproceedings{angizi2017energy,
  title={Energy Efficient In-memory Computing Platform based on 4-terminal Spin Hall Effect-driven Domain Wall Motion Devices},
  author={Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={Proceedings of the on Great Lakes Symposium on VLSI (GLSVLSI)},
  pages={77--82},
  year={2017},
  organization={ACM},
  keywords={conference},
  link={https://dl.acm.org/doi/10.1145/3060403.3060459}
}

@inproceedings{angizi2017rimpa,
  title={Rimpa: A new Reconfigurable Dual-mode In-memory Processing Architecture with Spin Hall Effect-driven Domain Wall Motion Device},
  author={Angizi, Shaahin and He, Zhezhi and Parveen, Farhana and Fan, Deliang},
  booktitle={2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={45--50},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/7987493}
}

@inproceedings{parveen2017hybrid2,
  title={Hybrid Polymorphic Logic Gate with 5-terminal Magnetic Domain Wall Motion Device},
  author={Parveen, Farhana and He, Zhezhi and Angizi, Shaahin and Fan, Deliang},
  booktitle={IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={152--157},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/7987511},
  award={Best Paper Award}
}

@inproceedings{fan2017memory,
  title={In-memory Computing with Spintronic Devices},
  author={Fan, Deliang and Angizi, Shaahin and He, Zhezhi},
  booktitle={IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={683--688},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/7987602}
}

@inproceedings{parveen2017low,
  title={Low Power In-memory Computing based on Dual-mode SOT-MRAM},
  author={Parveen, Farhana and Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={2017 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED)},
  pages={1--6},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/8009200}
}

@inproceedings{parveen2017hybrid1,
  title={Hybrid Polymorphic Logic Gate using 6 Terminal Magnetic Domain Wall Motion Device},
  author={Parveen, Farhana and Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
  booktitle={IEEE International Symposium on Circuits and Systems (ISCAS)},
  pages={1--4},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link={https://ieeexplore.ieee.org/abstract/document/8050921}
}

@inproceedings{fan2017leveraging,
  title={Leveraging Spintronic Devices for Ultra-low Power In-memory Computing: Logic and Neural Network},
  author={Fan, Deliang and He, Zhezhi and Angizi, Shaahin},
  booktitle={IEEE 60th International Midwest Symposium on Circuits and Systems (MWSCAS)},
  pages={1109--1112},
  year={2017},
  organization={IEEE},
  keywords  = {conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8053122}
}

@inproceedings{he2017high,
  title={High Performance and Energy-efficient In-memory Computing Architecture Based on SOT-MRAM},
  author={He, Zhezhi and Angizi, Shaahin and Parveen, Farhana and Fan, Deliang},
  booktitle={IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH)},
  pages={97--102},
  year={2017},
  organization={IEEE},
  keywords  = {conference},
  link ={https://ieeexplore.ieee.org/abstract/document/8053122}
}

@article{angizi2018design,
  title={Design and Evaluation of a Spintronic In-Memory Processing Platform for Nonvolatile Data Encryption},
  author={Angizi, Shaahin and He, Zhezhi and Bagherzadeh, Nader and Fan, Deliang},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (ICCAD)},
  volume={37},
  number={9},
  pages={1788--1801},
  year={2018},
  publisher={IEEE},
  keywords  = {journal},
  link = {https://ieeexplore.ieee.org/abstract/document/8053122}
}

@inproceedings{he2017exploring,
  title={Exploring STT-MRAM based In-memory Computing Paradigm with Application of Image Edge Extraction},
  author={He, Zhezhi and Angizi, Shaahin and Fan, Deliang},
  booktitle={2017 IEEE International Conference on Computer Design (ICCD)},
  pages={439--446},
  year={2017},
  organization={IEEE},
  keywords={conference},
  link = {https://ieeexplore.ieee.org/abstract/document/8119251}
}

@inproceedings{he2016low,
  title={A Low Power Current-mode Flash ADC with Spin Hall Effect Based Multi-threshold Comparator},
  author={He, Zhezhi and Fan, Deliang},
  booktitle={Proceedings of the 2016 International Symposium on Low Power Electronics and Design (ISLPED)},
  pages={314--319},
  year={2016},
  organization={ACM},
  keywords={conference},
  link={https://dl.acm.org/doi/10.1145/2934583.2934642}
}





